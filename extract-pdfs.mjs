#!/usr/bin/env node

import fs from 'fs';
import path from 'path';
import { createRequire } from 'module';
import { fileURLToPath } from 'url';

const __dirname = path.dirname(fileURLToPath(import.meta.url));
const require = createRequire(import.meta.url);
const PDFParse = require('pdf-parse');

async function extractTextFromPDF(buffer) {
  const data = await PDFParse(buffer);
  return data.text || '';
}

async function extractAndCacheAllPDFs() {
  const pdfsDir = path.join(process.cwd(), 'backend', 'pdfs');
  
  if (!fs.existsSync(pdfsDir)) {
    console.log('‚ö†Ô∏è  No backend/pdfs folder found. Skipping PDF extraction.');
    return;
  }

  const files = fs.readdirSync(pdfsDir).filter((f) => f.toLowerCase().endsWith('.pdf'));
  
  if (files.length === 0) {
    console.log('‚ö†Ô∏è  No PDFs found in backend/pdfs.');
    return;
  }

  const cache = {};

  console.log(`\nüîÑ Extracting ${files.length} PDF(s)...`);

  for (const filename of files) {
    try {
      const filePath = path.join(pdfsDir, filename);
      const fileBuffer = fs.readFileSync(filePath);
      
      const text = await extractTextFromPDF(fileBuffer);
      
      cache[filename] = {
        text,
        extractedAt: new Date().toISOString(),
      };

      console.log(`‚úÖ Extracted: ${filename} (${text.length} chars)`);
    } catch (err) {
      console.error(`‚ùå Failed to extract ${filename}:`, err);
    }
  }

  const cacheFile = path.join(process.cwd(), '.pdf-cache.json');
  fs.writeFileSync(cacheFile, JSON.stringify(cache, null, 2));
  console.log(`\nüì¶ PDF cache saved to .pdf-cache.json (${Object.keys(cache).length} files)\n`);
}

console.log('üöÄ Running PDF extraction build step...\n');

extractAndCacheAllPDFs()
  .then(() => {
    console.log('‚ú® PDF extraction complete!');
    process.exit(0);
  })
  .catch((err) => {
    console.error('‚ùå PDF extraction failed:', err);
    process.exit(1);
  });
